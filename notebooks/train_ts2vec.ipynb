{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e120b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt  # NEW: for line charts\n",
    "\n",
    "# Global settings / reproducibility\n",
    "cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Root path to UCRArchive_2018\n",
    "ROOT = r\"D:\\2025暑期科研\\UCRArchive_2018\\UCRArchive_2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b452a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_pad_timeseries(raw_2d, min_len=8, cap_len=None, pad_value=0.0,\n",
    "                             per_sample_standardize=True, fixed_len=None):\n",
    "    \"\"\"\n",
    "    Clean time series with tail NaNs, z-score per-sample (optional), and pad/clip.\n",
    "\n",
    "    Priority of output length:\n",
    "      1) fixed_len: if not None, output length = fixed_len (force)\n",
    "      2) cap_len:   if not None, output length = min(max_real_len, cap_len)\n",
    "      3) otherwise, output length = max_real_len of this input batch\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    N, T = raw_2d.shape\n",
    "    rows, keep_idx, real_lens = [], [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        row = raw_2d[i]\n",
    "        valid_vals = row[~np.isnan(row)]\n",
    "        L = valid_vals.shape[0]\n",
    "        if L < min_len:\n",
    "            continue\n",
    "        if per_sample_standardize:\n",
    "            mu = valid_vals.mean()\n",
    "            sigma = valid_vals.std()\n",
    "            valid_vals = (valid_vals - mu) / (sigma if sigma > 0 else 1.0)\n",
    "        rows.append(valid_vals); keep_idx.append(i); real_lens.append(L)\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        raise ValueError(\"All samples filtered out. Lower min_len if needed.\")\n",
    "\n",
    "    max_real_len = max(real_lens)\n",
    "    if fixed_len is not None:\n",
    "        target_len = int(fixed_len)\n",
    "    elif cap_len is not None:\n",
    "        target_len = min(max_real_len, cap_len)\n",
    "    else:\n",
    "        target_len = max_real_len\n",
    "\n",
    "    out = []\n",
    "    for arr in rows:\n",
    "        if arr.shape[0] >= target_len:\n",
    "            arr = arr[:target_len]\n",
    "        else:\n",
    "            arr = np.pad(arr, (0, target_len - arr.shape[0]), constant_values=pad_value)\n",
    "        out.append(arr)\n",
    "\n",
    "    X = np.stack(out, axis=0).astype(\"float32\")\n",
    "    return X, np.array(keep_idx, dtype=np.int64), np.array(real_lens, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11084cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Two-tower Transformer:\n",
    "      - Tower 1: time series tokens [B, T, 1] -> embed -> transformer\n",
    "      - Tower 2: Aout vector [B, F] as a single token -> embed -> transformer\n",
    "      - Concat tokens -> final transformer -> flatten -> FC for multi-class logits\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim1, input_dim2,\n",
    "                 hidden_dim1, hidden_dim2, hidden_dim3,\n",
    "                 num_heads, num_layers, num_classes,\n",
    "                 seq_len1, seq_len2):\n",
    "        super().__init__()\n",
    "        # To keep it simple we force equal hidden dims and divisibility by nhead\n",
    "        assert hidden_dim1 == hidden_dim2 == hidden_dim3, \"hidden dims must be equal in this version.\"\n",
    "        for h in (hidden_dim1, hidden_dim2, hidden_dim3):\n",
    "            assert h % num_heads == 0, \"hidden_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.embedding1 = nn.Linear(input_dim1, hidden_dim1)\n",
    "        self.embedding2 = nn.Linear(input_dim2, hidden_dim2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.transformer1 = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_dim1, nhead=num_heads, batch_first=True),\n",
    "            num_layers=num_layers)\n",
    "\n",
    "        self.transformer2 = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_dim2, nhead=num_heads, batch_first=True),\n",
    "            num_layers=num_layers)\n",
    "\n",
    "        self.final_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_dim3, nhead=num_heads, batch_first=True),\n",
    "            num_layers=num_layers)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.seq_len1 = seq_len1\n",
    "        self.seq_len2 = 1  # treat Aout as a single token\n",
    "        fc_in = hidden_dim3 * (seq_len1 + self.seq_len2)\n",
    "        self.fc = nn.Linear(fc_in, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1: [B, T, input_dim1], x2: [B, F] or [B, 1, F]\n",
    "        if x1.dim() == 2:\n",
    "            x1 = x1.unsqueeze(-1)\n",
    "        x1 = self.relu(self.embedding1(x1))\n",
    "        x1 = self.transformer1(x1)\n",
    "\n",
    "        if x2.dim() == 3:\n",
    "            assert x2.size(1) == 1, \"Expect x2 with L2=1 if 3D\"\n",
    "            x2 = x2.squeeze(1)\n",
    "        x2 = self.relu(self.embedding2(x2))\n",
    "        x2 = x2.unsqueeze(1)\n",
    "        x2 = self.transformer2(x2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.final_transformer(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class VisitDataset(Dataset):\n",
    "    \"\"\"Simple tensor dataset for (visit time series, aout features, one-hot labels).\"\"\"\n",
    "    def __init__(self, visit_x, aout_x, y):\n",
    "        self.visit_x = visit_x.astype(\"float32\")\n",
    "        self.aout_x  = aout_x.astype(\"float32\")\n",
    "        self.y       = y.astype(\"float32\")\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.visit_x[idx], self.aout_x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3cddd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Backbones: Informer / FEDformer (Encoder-only Classifiers) =====\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LearnedPositionalEncoding(nn.Module):\n",
    "    def __init__(self, seq_len: int, d_model: int, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.pe = nn.Parameter(torch.zeros(1, seq_len, d_model))\n",
    "        nn.init.trunc_normal_(self.pe, std=0.02)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[:, :x.size(1), :])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(input_dim, d_model)\n",
    "    def forward(self, x):  # x: [B, L, C]\n",
    "        return self.proj(x)\n",
    "\n",
    "class InformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=256, n_heads=4, d_ff=512, dropout=0.1, attn_dropout=0.1, activation='gelu'):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, n_heads, dropout=attn_dropout, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU() if activation.lower()=='gelu' else nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
    "        attn_out, _ = self.self_attn(x, x, x, attn_mask=attn_mask, key_padding_mask=key_padding_mask, need_weights=False)\n",
    "        x = self.norm1(x + self.dropout1(attn_out))\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout2(ff_out))\n",
    "        return x\n",
    "\n",
    "class DistilConv1D(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(d_model, d_model, kernel_size=3, stride=2, padding=1)\n",
    "        self.norm = nn.BatchNorm1d(d_model)\n",
    "        self.act = nn.ELU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    def forward(self, x):  # [B, L, D]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        return x.transpose(1, 2)\n",
    "\n",
    "class InformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model=256, n_heads=4, e_layers=2, d_ff=512, dropout=0.1, distil=True, attn_dropout=0.1, activation='gelu'):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            InformerEncoderLayer(d_model, n_heads, d_ff, dropout, attn_dropout, activation)\n",
    "            for _ in range(e_layers)\n",
    "        ])\n",
    "        self.distil_layers = nn.ModuleList([DistilConv1D(d_model, dropout=dropout) for _ in range(e_layers-1)]) if distil and e_layers>1 else None\n",
    "    def forward(self, x):  # [B, L, D]\n",
    "        if self.distil_layers is None:\n",
    "            for enc in self.layers: x = enc(x)\n",
    "            return x\n",
    "        for i,enc in enumerate(self.layers):\n",
    "            x = enc(x)\n",
    "            if i < len(self.layers)-1: x = self.distil_layers[i](x)\n",
    "        return x\n",
    "\n",
    "# ====== REPLACE in Cell 4: FourierBlock & FEDEncoderLayer ======\n",
    "\n",
    "class FourierAttentionLike(nn.Module):\n",
    "    \"\"\"\n",
    "    '更贴近官方'的频域块：\n",
    "    - rFFT 得到频域\n",
    "    - 选能量最大的 top-k 频率（按 batch 的平均能量统计，不会引入数据泄漏）\n",
    "    - 对选中的频率施加【可学习的复权重】(幅度 + 相位)\n",
    "    - iFFT 回时域\n",
    "    仍然是 Encoder 内的一个子层，用作“频域相关性”的近似。\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, k_ratio: float = 0.25):\n",
    "        super().__init__()\n",
    "        self.k_ratio = k_ratio\n",
    "        # 可学习的幅度与相位（简化：对所有通道共享一组权重；也可换成 per-channel）\n",
    "        self.scale = nn.Parameter(torch.ones(1))          # 幅度缩放\n",
    "        self.phase = nn.Parameter(torch.zeros(1))         # 相位偏移（弧度）\n",
    "        self.proj_in  = nn.Identity()                     # 你也可以放个 1x1 线性层\n",
    "        self.proj_out = nn.Identity()\n",
    "\n",
    "    def forward(self, x):  # x: [B, L, D]\n",
    "        B, L, D = x.shape\n",
    "        x = self.proj_in(x)\n",
    "\n",
    "        # FFT：对时间维做 rFFT -> 形状 [B, F, D]，F = L//2 + 1\n",
    "        Xf = torch.fft.rfft(x, dim=1)\n",
    "\n",
    "        # 频率能量（幅度平方），取 batch&channel 平均，得到每个频率的能量\n",
    "        energy = (Xf.real**2 + Xf.imag**2).mean(dim=(0, 2))  # [F]\n",
    "        F = Xf.size(1)\n",
    "        k = max(1, int(F * self.k_ratio))\n",
    "\n",
    "        # top-k 频率索引（按能量挑最重要的频率）\n",
    "        topk_idx = torch.topk(energy, k=k, largest=True, sorted=False).indices\n",
    "\n",
    "        # 构造一个 mask 仅保留 top-k 频率\n",
    "        mask = torch.zeros(F, device=Xf.device, dtype=Xf.dtype)\n",
    "        mask[topk_idx] = 1.0\n",
    "        mask = mask.view(1, F, 1)  # broadcast 到 [B, F, D]\n",
    "\n",
    "        # 对保留的频率应用可学习复权重：scale * exp(j*phase)\n",
    "        complex_weight = self.scale * torch.complex(\n",
    "            torch.cos(self.phase), torch.sin(self.phase)\n",
    "        )  # 标量复数\n",
    "        Xf = Xf * mask * complex_weight\n",
    "\n",
    "        # 反变换回时域\n",
    "        y = torch.fft.irfft(Xf, n=L, dim=1)\n",
    "        y = self.proj_out(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class FEDEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=256, d_ff=512, dropout=0.1, activation='gelu', k_ratio=0.25):\n",
    "        super().__init__()\n",
    "        # 用上面“更贴近官方”的频域相关性近似块\n",
    "        self.fourier = FourierAttentionLike(d_model=d_model, k_ratio=k_ratio)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU() if activation.lower()=='gelu' else nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 频域相关性（残差）\n",
    "        z = self.fourier(x)\n",
    "        x = self.norm1(x + self.dropout1(z))\n",
    "        # FFN（残差）\n",
    "        z2 = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout2(z2))\n",
    "        return x\n",
    "\n",
    "class FEDformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model=256, e_layers=2, d_ff=512, dropout=0.1, activation='gelu', k_ratio=0.25):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([FEDEncoderLayer(d_model, d_ff, dropout, activation, k_ratio) for _ in range(e_layers)])\n",
    "    def forward(self, x):\n",
    "        for enc in self.layers: x = enc(x)\n",
    "        return x\n",
    "\n",
    "class TimePoolClassifierHead(nn.Module):\n",
    "    def __init__(self, d_model: int, num_classes: int, pool: str = \"mean\", dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert pool in (\"mean\",\"max\",\"cls\")\n",
    "        self.pool = pool\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1,1,d_model)) if pool==\"cls\" else None\n",
    "        if self.cls_token is not None: nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "    def forward(self, x):  # [B, L, D]\n",
    "        if self.pool==\"mean\":\n",
    "            h = x.mean(dim=1)\n",
    "        elif self.pool==\"max\":\n",
    "            h,_ = x.max(dim=1)\n",
    "        else:\n",
    "            h = x[:,0,:]\n",
    "        h = self.dropout(h)\n",
    "        return self.fc(h)\n",
    "\n",
    "class InformerEncoderClassifier(nn.Module):\n",
    "    \"\"\"Drop-in 替换 TwoTower；forward(x1,x2) 忽略 x2；x1=[B,L,1]\"\"\"\n",
    "    def __init__(self, input_dim:int, num_classes:int, seq_len:int,\n",
    "                 d_model=256, n_heads=4, e_layers=2, d_ff=512,\n",
    "                 dropout=0.1, attn_dropout=0.1, distil=True, activation='gelu', pool=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.token = TokenEmbedding(input_dim, d_model)\n",
    "        self.pos = LearnedPositionalEncoding(seq_len, d_model, dropout)\n",
    "        self.encoder = InformerEncoder(d_model, n_heads, e_layers, d_ff, dropout, distil, attn_dropout, activation)\n",
    "        self.head = TimePoolClassifierHead(d_model, num_classes, pool, dropout)\n",
    "    def forward(self, x1, x2=None):\n",
    "        if x1.dim()==2: x1 = x1.unsqueeze(-1)\n",
    "        x = self.token(x1); x = self.pos(x); x = self.encoder(x)\n",
    "        return self.head(x)\n",
    "\n",
    "class FEDformerEncoderClassifier(nn.Module):\n",
    "    \"\"\"Drop-in 替换 TwoTower；forward(x1,x2) 忽略 x2；x1=[B,L,1]\"\"\"\n",
    "    def __init__(self, input_dim:int, num_classes:int, seq_len:int,\n",
    "                 d_model=256, e_layers=2, d_ff=512, dropout=0.1, activation='gelu', k_ratio=0.25, pool=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.token = TokenEmbedding(input_dim, d_model)\n",
    "        self.pos = LearnedPositionalEncoding(seq_len, d_model, dropout)\n",
    "        self.encoder = FEDformerEncoder(d_model, e_layers, d_ff, dropout, activation, k_ratio)\n",
    "        self.head = TimePoolClassifierHead(d_model, num_classes, pool, dropout)\n",
    "    def forward(self, x1, x2=None):\n",
    "        if x1.dim()==2: x1 = x1.unsqueeze(-1)\n",
    "        x = self.token(x1); x = self.pos(x); x = self.encoder(x)\n",
    "        return self.head(x)\n",
    "    \n",
    "# === TS2Vec helpers: 自监督预训练 + 线性探针 ===\n",
    "# 依赖：请把官方仓库的 ts2vec.py、models/*.py、utils/*.py 放到你的工程目录里（或同级子目录并做好 import）\n",
    "from ts2vec import TS2Vec\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def ts2vec_linear_probe(\n",
    "    visit_tr, visit_te,             # np array: [N, L, 1] （左塔）\n",
    "    Y_tr, Y_te,                     # one-hot labels\n",
    "    device,\n",
    "    batch_size=8,\n",
    "    pretrain_iters=None,            # 若为 None，走官方默认（<=1e5元素 200iters，否则 600）\n",
    "    pretrain_epochs=None,           # 二选一，给 iters 或 epochs\n",
    "    encoder_hidden=64,\n",
    "    encoder_depth=10,\n",
    "    proj_dim=320,\n",
    "    lr=1e-4,                        # 为公平，用你全局 lr；若要更贴近官方，可把这项设为1e-3\n",
    "    head_epochs=100,                # 用与你主干一致的 num_epochs\n",
    "    patience=15                     # 只对 head(监督)训练早停；自监督阶段不早停\n",
    "):\n",
    "    assert visit_tr.ndim == 3 and visit_tr.shape[-1] == 1\n",
    "    assert visit_te.ndim == 3 and visit_te.shape[-1] == 1\n",
    "    # --- 1) 自监督预训练（只用 train） ---\n",
    "    ts2 = TS2Vec(\n",
    "        input_dims=1,\n",
    "        output_dims=proj_dim,\n",
    "        hidden_dims=encoder_hidden,\n",
    "        depth=encoder_depth,\n",
    "        device=device,\n",
    "        lr=lr,                 # 如想更贴近官方，可单独设 lr=1e-3\n",
    "        batch_size=batch_size,\n",
    "        max_train_length=None, # 我们已做同长，不再额外切窗\n",
    "        temporal_unit=0\n",
    "    )\n",
    "    # 官方 fit 支持 n_iters 或 n_epochs；给一个即可\n",
    "    loss_log = ts2.fit(\n",
    "        train_data=visit_tr, \n",
    "        n_iters=pretrain_iters, \n",
    "        n_epochs=pretrain_epochs, \n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # --- 2) 编码为全序列表征（train/test 各得到一个向量表示） ---\n",
    "    # encoding_window='full_series' 会做全序列 max-pool，输出 [N, 1, proj_dim] -> squeeze 到 [N, proj_dim]\n",
    "    z_tr = ts2.encode(visit_tr, encoding_window='full_series')  # -> [Ntr, D]\n",
    "    z_te = ts2.encode(visit_te, encoding_window='full_series')  # -> [Nte, D]\n",
    "\n",
    "    # --- 3) 线性探针分类头（监督训练，与你现有超参/早停一致） ---\n",
    "    num_classes = Y_tr.shape[1]\n",
    "    z_tr_t = torch.from_numpy(z_tr).to(device=device, dtype=torch.float32)\n",
    "    z_te_t = torch.from_numpy(z_te).to(device=device, dtype=torch.float32)\n",
    "    y_tr_t = torch.from_numpy(Y_tr).to(device=device, dtype=torch.float32)\n",
    "    y_te_t = torch.from_numpy(Y_te).to(device=device, dtype=torch.float32)\n",
    "\n",
    "    head = nn.Linear(proj_dim, num_classes).to(device)\n",
    "    optim_head = torch.optim.Adam(head.parameters(), lr=lr)\n",
    "    sched_head = torch.optim.lr_scheduler.CosineAnnealingLR(optim_head, T_max=50, eta_min=0.0)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # 简单的张量版 mini-batch loader\n",
    "    def iter_minibatch(X, Y, bs):\n",
    "        n = X.size(0)\n",
    "        idx = torch.randperm(n, device=X.device)\n",
    "        for i in range(0, n, bs):\n",
    "            j = idx[i:i+bs]\n",
    "            yield X[j], Y[j]\n",
    "\n",
    "    class _ES:\n",
    "        def __init__(self, patience=15, delta=0.0):\n",
    "            self.pat = patience; self.delta=delta\n",
    "            self.best=None; self.count=0; self.stop=False\n",
    "        def step(self, loss):\n",
    "            if self.best is None: self.best = loss; return False\n",
    "            if loss > self.best - self.delta:\n",
    "                self.count += 1\n",
    "                if self.count >= self.pat: self.stop=True\n",
    "            else:\n",
    "                self.best = loss; self.count=0\n",
    "            return self.stop\n",
    "    es = _ES(patience=patience)\n",
    "\n",
    "    # 监督阶段：只看 TrainLoss 早停（与你现在管线一致）\n",
    "    for ep in range(head_epochs):\n",
    "        head.train()\n",
    "        tot=0.0; steps=0\n",
    "        for xb, yb in iter_minibatch(z_tr_t, y_tr_t, batch_size):\n",
    "            optim_head.zero_grad()\n",
    "            logits = head(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward(); optim_head.step()\n",
    "            tot += loss.item(); steps+=1\n",
    "        sched_head.step()\n",
    "        avg_train_loss = tot / max(1,steps)\n",
    "        if es.step(avg_train_loss): break\n",
    "\n",
    "    # --- 4) 最终 Test 一次性评估 ---\n",
    "    head.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = head(z_te_t).detach().cpu().numpy()\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "    y_true = y_te_t.detach().cpu().numpy()\n",
    "    try:\n",
    "        test_auc = roc_auc_score(y_true, logits, multi_class='ovr')\n",
    "    except:\n",
    "        test_auc = roc_auc_score(y_true, logits)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    y_cls  = np.argmax(y_true,  axis=1)\n",
    "    test_acc = accuracy_score(y_cls, y_pred)\n",
    "    return float(test_auc), float(test_acc), int(y_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af3eead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- TS2Vec 预训练 + 线性探针（分类头） ----\n",
    "from ts2vec import TS2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def ts2vec_linear_probe(\n",
    "    visit_tr, visit_te,            # np: [N, L, 1]\n",
    "    Y_tr, Y_te,                    # one-hot\n",
    "    device='cuda:0',\n",
    "    batch_size=8,\n",
    "    pretrain_iters=None,           # 不给就用官方默认\n",
    "    pretrain_epochs=None,\n",
    "    encoder_hidden=64,\n",
    "    encoder_depth=10,\n",
    "    proj_dim=320,\n",
    "    lr=1e-4,                       # 与 twotower 保持一致；若想更像官方可单独设 1e-3\n",
    "    head_epochs=100,\n",
    "    patience=15\n",
    "):\n",
    "    # 1) 自监督：仅用 train 做 TS2Vec 预训练\n",
    "    ts2 = TS2Vec(\n",
    "        input_dims=1,\n",
    "        output_dims=proj_dim,\n",
    "        hidden_dims=encoder_hidden,\n",
    "        depth=encoder_depth,\n",
    "        device=device,\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        max_train_length=None,\n",
    "        temporal_unit=0\n",
    "    )\n",
    "    _ = ts2.fit(\n",
    "        train_data=visit_tr,\n",
    "        n_iters=pretrain_iters,\n",
    "        n_epochs=pretrain_epochs,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # 2) 得到整序列的表示（注意：内部已 squeeze 到 [N, D]，外面别再 squeeze）\n",
    "    z_tr = ts2.encode(visit_tr, encoding_window='full_series')\n",
    "    z_te = ts2.encode(visit_te, encoding_window='full_series')\n",
    "\n",
    "    # 3) 线性探针（与你主流程保持同损失/优化器/早停策略）\n",
    "    X_tr = torch.from_numpy(z_tr).to(torch.float32).to(device)\n",
    "    X_te = torch.from_numpy(z_te).to(torch.float32).to(device)\n",
    "    y_tr = torch.from_numpy(Y_tr).to(torch.float32).to(device)\n",
    "    y_te = torch.from_numpy(Y_te).to(torch.float32).to(device)\n",
    "\n",
    "    head = nn.Linear(X_tr.shape[1], y_tr.shape[1]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(head.parameters(), lr=lr)\n",
    "\n",
    "    class EarlyStopping:\n",
    "        def __init__(self, patience=15, delta=0.0):\n",
    "            self.patience = patience; self.delta = delta\n",
    "            self.counter = 0; self.best = None; self.stop = False\n",
    "        def step(self, loss):\n",
    "            if self.best is None: self.best = loss; return False\n",
    "            if loss > self.best - self.delta:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience: self.stop = True\n",
    "            else:\n",
    "                self.best = loss; self.counter = 0\n",
    "            return self.stop\n",
    "    es = EarlyStopping(patience=patience)\n",
    "\n",
    "    # 简单的小 batchloader（向量分类）\n",
    "    ds = torch.utils.data.TensorDataset(X_tr, y_tr)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    import numpy as np\n",
    "    for epoch in range(head_epochs):\n",
    "        head.train()\n",
    "        total = 0.0\n",
    "        for xb, yb in dl:\n",
    "            optimizer.zero_grad()\n",
    "            logits = head(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward(); optimizer.step()\n",
    "            total += loss.item()\n",
    "        avg_loss = total / max(1, len(dl))\n",
    "        if es.step(avg_loss): break\n",
    "\n",
    "    # 测试\n",
    "    head.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = head(X_te).detach().cpu().numpy()\n",
    "        labs   = y_te.detach().cpu().numpy()\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "    try:  auc = roc_auc_score(labs, logits, multi_class='ovr')\n",
    "    except: auc = roc_auc_score(labs, logits)\n",
    "    pred = logits.argmax(1); true = labs.argmax(1)\n",
    "    acc = accuracy_score(true, pred)\n",
    "    return float(auc), float(acc), int(labs.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676aa115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_dataset(dataset_dir, dataset_name,\n",
    "                    device='cuda:0',\n",
    "                    batch_size=8, num_epochs=100, lr=1e-4,\n",
    "                    cap_len=None, patience=15,\n",
    "                    verbose=False, plot_curves=True,\n",
    "                    backbone='twotower'):\n",
    "    import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "    import torch, torch.nn as nn, torch.optim as optim\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "    from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "    # ---------- 路径 ----------\n",
    "    tsv_train_path = os.path.join(dataset_dir, f\"{dataset_name}_TRAIN_cleaned.tsv\")\n",
    "    tsv_test_path  = os.path.join(dataset_dir, f\"{dataset_name}_TEST_cleaned.tsv\")\n",
    "    aout_train_csv = os.path.join(dataset_dir, f\"{dataset_name}_Aout_train_k2.csv\")\n",
    "    aout_test_csv  = os.path.join(dataset_dir, f\"{dataset_name}_Aout_test_k2.csv\")\n",
    "    if not all(os.path.exists(p) for p in [tsv_train_path, tsv_test_path, aout_train_csv, aout_test_csv]):\n",
    "        print(f\"⚠ Skip {dataset_name}, missing files\"); return None\n",
    "\n",
    "    # ---------- 读取 ----------\n",
    "    tsv_tr = pd.read_csv(tsv_train_path, sep=\"\\t\", header=None)\n",
    "    tsv_te = pd.read_csv(tsv_test_path,  sep=\"\\t\", header=None)\n",
    "    csv_tr = pd.read_csv(aout_train_csv, header=None)\n",
    "    csv_te = pd.read_csv(aout_test_csv,  header=None)\n",
    "\n",
    "    y_tr_raw = tsv_tr.iloc[:,0].values\n",
    "    y_te_raw = tsv_te.iloc[:,0].values\n",
    "    visit_tr_raw = tsv_tr.iloc[:,1:].values.astype(\"float32\")\n",
    "    visit_te_raw = tsv_te.iloc[:,1:].values.astype(\"float32\")\n",
    "    aout_tr_raw_all  = csv_tr.iloc[:,1:].values.astype(\"float32\")\n",
    "    aout_te_raw_all  = csv_te.iloc[:,1:].values.astype(\"float32\")\n",
    "\n",
    "    # ---------- Train 决定参考长度 ----------\n",
    "    tmp_train_clean, keep_tr0, _ = clean_and_pad_timeseries(\n",
    "        visit_tr_raw, min_len=8, cap_len=None, pad_value=0.0,\n",
    "        per_sample_standardize=True, fixed_len=None\n",
    "    )\n",
    "    train_seq_len = tmp_train_clean.shape[1]\n",
    "\n",
    "    # ---------- 固定同长清洗（官方A方案） ----------\n",
    "    visit_tr_clean, keep_tr, _ = clean_and_pad_timeseries(\n",
    "        visit_tr_raw, min_len=8, cap_len=None, pad_value=0.0,\n",
    "        per_sample_standardize=True, fixed_len=train_seq_len\n",
    "    )\n",
    "    y_tr = y_tr_raw[keep_tr]\n",
    "    aout_tr_raw = aout_tr_raw_all[keep_tr]\n",
    "\n",
    "    visit_te_clean, keep_te, _ = clean_and_pad_timeseries(\n",
    "        visit_te_raw, min_len=8, cap_len=None, pad_value=0.0,\n",
    "        per_sample_standardize=True, fixed_len=train_seq_len\n",
    "    )\n",
    "    y_te = y_te_raw[keep_te]\n",
    "    aout_te_raw = aout_te_raw_all[keep_te]\n",
    "\n",
    "    # ---------- 右塔标准化（fit on train, apply to test） ----------\n",
    "    scaler = StandardScaler().fit(aout_tr_raw)\n",
    "    aout_tr = scaler.transform(aout_tr_raw).astype(\"float32\")\n",
    "    aout_te = scaler.transform(aout_te_raw).astype(\"float32\")\n",
    "\n",
    "    # ---------- One-hot 标签 ----------\n",
    "    classes = sorted(np.unique(y_tr))\n",
    "    Y_tr = label_binarize(y_tr, classes=classes).astype(\"float32\")\n",
    "    Y_te = label_binarize(y_te, classes=classes).astype(\"float32\")\n",
    "\n",
    "    # ---------- 左塔输入形状 [B, L, 1] ----------\n",
    "    visit_tr = visit_tr_clean[:, :, None]\n",
    "    visit_te = visit_te_clean[:, :, None]\n",
    "\n",
    "    # ===== TS2Vec 分支（自监督 + 线性探针；不实例化 PyTorch 分类模型） =====\n",
    "    if backbone.lower() in ('ts2vec', 'ts2vec_lp'):\n",
    "        device_t = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        test_auc, test_acc, test_n = ts2vec_linear_probe(\n",
    "            visit_tr=visit_tr, visit_te=visit_te,\n",
    "            Y_tr=Y_tr, Y_te=Y_te,\n",
    "            device=device_t,\n",
    "            batch_size=batch_size,\n",
    "            pretrain_iters=None,       # 官方默认：<=1e5元素 200，否则 600\n",
    "            pretrain_epochs=None,\n",
    "            encoder_hidden=64,         # 贴近官方\n",
    "            encoder_depth=10,          # 贴近官方\n",
    "            proj_dim=320,              # 贴近官方\n",
    "            lr=lr,                     # 为公平，用你的全局 lr\n",
    "            head_epochs=num_epochs,    # 线性头与其他骨干对齐\n",
    "            patience=patience\n",
    "        )\n",
    "        print(f\"[{dataset_name} | ts2vec] TEST AUC={test_auc:.4f}, TEST ACC={test_acc:.4f}, n_samples={test_n}\")\n",
    "        return test_auc, test_acc, test_n\n",
    "\n",
    "    # ===== 其余骨干（TwoTower / Informer / FEDformer）保持不变 =====\n",
    "    seq_len1 = visit_tr.shape[1]\n",
    "    input_dim1 = visit_tr.shape[2]\n",
    "    input_dim2 = aout_tr.shape[1]   # TwoTower 用；单塔忽略\n",
    "    num_classes = Y_tr.shape[1]\n",
    "\n",
    "    device_torch = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 构建模型\n",
    "    if backbone.lower() == 'twotower':\n",
    "        hidden_dim1 = hidden_dim2 = hidden_dim3 = 16\n",
    "        num_heads = 2; num_layers = 2; seq_len2 = 1\n",
    "        model = TwoTowerTransformer(\n",
    "            input_dim1, input_dim2,\n",
    "            hidden_dim1, hidden_dim2, hidden_dim3,\n",
    "            num_heads, num_layers,\n",
    "            num_classes,\n",
    "            seq_len1, seq_len2\n",
    "        ).to(device_torch)\n",
    "\n",
    "    elif backbone.lower() == 'informer':\n",
    "        model = InformerEncoderClassifier(\n",
    "            input_dim=1, num_classes=num_classes, seq_len=seq_len1,\n",
    "            d_model=256, n_heads=4, e_layers=2, d_ff=512,\n",
    "            dropout=0.1, attn_dropout=0.1, distil=True, activation='gelu', pool='mean'\n",
    "        ).to(device_torch)\n",
    "\n",
    "    elif backbone.lower() in ('fed', 'fedformer'):\n",
    "        model = FEDformerEncoderClassifier(\n",
    "            input_dim=1, num_classes=num_classes, seq_len=seq_len1,\n",
    "            d_model=256, e_layers=2, d_ff=512,\n",
    "            dropout=0.1, activation='gelu', k_ratio=0.25, pool='mean'\n",
    "        ).to(device_torch)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n",
    "\n",
    "    # 多卡\n",
    "    if torch.cuda.device_count() > 1 and str(device_torch).startswith('cuda'):\n",
    "        model = nn.DataParallel(model, device_ids=[0,1])\n",
    "    model = model.to(device_torch)\n",
    "\n",
    "    # DataLoader\n",
    "    train_loader = DataLoader(VisitDataset(visit_tr, aout_tr, Y_tr),\n",
    "                              batch_size=batch_size, shuffle=True,  pin_memory=True, num_workers=0)\n",
    "    test_loader  = DataLoader(VisitDataset(visit_te, aout_te, Y_te),\n",
    "                              batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # 优化器/损失/调度\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
    "\n",
    "    # 仅基于训练损失的早停\n",
    "    class EarlyStopping:\n",
    "        def __init__(self, patience=15, delta=0.0):\n",
    "            self.patience = patience; self.delta = delta\n",
    "            self.counter = 0; self.best = None; self.stop = False\n",
    "        def step(self, train_loss):\n",
    "            if self.best is None: self.best = train_loss; return False\n",
    "            if train_loss > self.best - self.delta:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience: self.stop = True\n",
    "            else:\n",
    "                self.best = train_loss; self.counter = 0\n",
    "            return self.stop\n",
    "    es = EarlyStopping(patience=patience)\n",
    "\n",
    "    # 训练（只记录 TrainLoss）\n",
    "    log_dir = os.path.join(dataset_dir, \"_twotower_logs\"); os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = open(os.path.join(log_dir, f\"log_{backbone}.txt\"), \"w\", encoding=\"utf-8\")\n",
    "    train_loss_hist = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for x1,x2,y in train_loader:\n",
    "            x1 = x1.to(torch.float32).to(device_torch)\n",
    "            x2 = x2.to(torch.float32).to(device_torch)\n",
    "            y  = y.to(torch.float32).to(device_torch)\n",
    "            optimizer.zero_grad()\n",
    "            o = model(x1,x2)   # 单塔会忽略 x2\n",
    "            l = criterion(o,y)\n",
    "            l.backward(); optimizer.step()\n",
    "            total_loss += l.item()\n",
    "        scheduler.step()\n",
    "        avg_train_loss = total_loss / max(1,len(train_loader))\n",
    "        train_loss_hist.append(avg_train_loss)\n",
    "        log_file.write(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {avg_train_loss:.4f}\\n\")\n",
    "        if es.step(avg_train_loss): break\n",
    "    log_file.close()\n",
    "\n",
    "    # 画 TrainLoss\n",
    "    if plot_curves and len(train_loss_hist)>0:\n",
    "        fig,ax=plt.subplots(figsize=(6,4))\n",
    "        ax.plot(range(1,len(train_loss_hist)+1), train_loss_hist, label=\"Train Loss\")\n",
    "        ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Loss\"); ax.grid(True); ax.legend()\n",
    "        ax.set_title(f\"{dataset_name} - {backbone} - Train Loss\")\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(log_dir, f\"{dataset_name}_{backbone}_train_loss.png\"), dpi=150); plt.show()\n",
    "\n",
    "    # TEST（一次性评估）\n",
    "    model.eval()\n",
    "    tout=[]; tlab=[]\n",
    "    with torch.no_grad():\n",
    "        for x1,x2,y in test_loader:\n",
    "            x1 = x1.to(torch.float32).to(device_torch)\n",
    "            x2 = x2.to(torch.float32).to(device_torch)\n",
    "            o = model(x1,x2)\n",
    "            tout.append(o.detach().cpu().numpy()); tlab.append(y.numpy())\n",
    "    tout = np.concatenate(tout); tlab = np.concatenate(tlab)\n",
    "    try:  test_auc = roc_auc_score(tlab, tout, multi_class='ovr')\n",
    "    except: test_auc = roc_auc_score(tlab, tout)\n",
    "    test_pred = np.argmax(tout, axis=1)\n",
    "    test_true = np.argmax(tlab, axis=1)\n",
    "    test_acc = accuracy_score(test_true, test_pred)\n",
    "    test_n = len(tlab)\n",
    "\n",
    "    print(f\"[{dataset_name} | {backbone}] TEST AUC={test_auc:.4f}, TEST ACC={test_acc:.4f}, n_samples={test_n}\")\n",
    "    return test_auc, test_acc, test_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63977695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_datasets(root):\n",
    "    \"\"\"\n",
    "    Discover dataset subfolders that contain all four required files:\n",
    "      *_TRAIN_cleaned.tsv, *_TEST_cleaned.tsv, *_Aout_train_k2.csv, *_Aout_test_k2.csv\n",
    "    Returns: a sorted list of dataset names (folder names).\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    for name in sorted(os.listdir(root)):\n",
    "        subdir = os.path.join(root, name)\n",
    "        if not os.path.isdir(subdir):\n",
    "            continue\n",
    "        t_train = os.path.join(subdir, f\"{name}_TRAIN_cleaned.tsv\")\n",
    "        t_test  = os.path.join(subdir, f\"{name}_TEST_cleaned.tsv\")\n",
    "        a_train = os.path.join(subdir, f\"{name}_Aout_train_k2.csv\")\n",
    "        a_test  = os.path.join(subdir, f\"{name}_Aout_test_k2.csv\")\n",
    "        if all(os.path.exists(p) for p in [t_train, t_test, a_train, a_test]):\n",
    "            names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64bb6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_datasets(root, device='cuda:0',\n",
    "                     batch_size=8, num_epochs=100, lr=1e-4,\n",
    "                     cap_len=None, verbose=False, plot_curves=True,\n",
    "                     patience=15, backbone='twotower'):\n",
    "    import os, pandas as pd\n",
    "    from datetime import datetime\n",
    "\n",
    "    dataset_names = discover_datasets(root)\n",
    "    print(f\"Found {len(dataset_names)} datasets:\", dataset_names)\n",
    "\n",
    "    rows = []\n",
    "    for name in dataset_names:\n",
    "        out = run_one_dataset(\n",
    "            dataset_dir=os.path.join(root, name),\n",
    "            dataset_name=name,\n",
    "            device=device,\n",
    "            batch_size=batch_size, num_epochs=num_epochs, lr=lr,\n",
    "            cap_len=cap_len, patience=patience,\n",
    "            verbose=verbose, plot_curves=plot_curves,\n",
    "            backbone=backbone   # <-- 透传骨干\n",
    "        )\n",
    "        if out is None: continue\n",
    "        test_auc, test_acc, test_n = out\n",
    "        rows.append((name, test_auc, test_acc, test_n))\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No dataset finished successfully.\"); return None\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"dataset\", \"test_auc\", \"test_acc\", \"n_samples\"])\n",
    "    mean_auc = df[\"test_auc\"].mean(); mean_acc = df[\"test_acc\"].mean()\n",
    "    w_auc = (df[\"test_auc\"] * df[\"n_samples\"]).sum() / df[\"n_samples\"].sum()\n",
    "    w_acc = (df[\"test_acc\"] * df[\"n_samples\"]).sum() / df[\"n_samples\"].sum()\n",
    "\n",
    "    print(\"\\n========== Summary (OFFICIAL TEST) ==========\")\n",
    "    print(df.sort_values(\"dataset\").to_string(index=False))\n",
    "    print(f\"\\nSimple mean: AUC = {mean_auc:.4f}, ACC = {mean_acc:.4f}\")\n",
    "    print(f\"Weighted (by samples): AUC = {w_auc:.4f}, ACC = {w_acc:.4f}\")\n",
    "\n",
    "    summary_dir = os.path.join(root, \"_twotower_logs\"); os.makedirs(summary_dir, exist_ok=True)\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    tag = backbone.lower()\n",
    "    df.to_csv(os.path.join(summary_dir, f\"summary_TEST_{tag}_{ts}.csv\"), index=False, encoding=\"utf-8\")\n",
    "    with open(os.path.join(summary_dir, f\"summary_TEST_{tag}_{ts}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(df.sort_values(\"dataset\").to_string(index=False))\n",
    "        f.write(f\"\\n\\nSimple mean: AUC={mean_auc:.6f}, ACC={mean_acc:.6f}\\n\")\n",
    "        f.write(f\"Weighted (by samples): AUC={w_auc:.6f}, ACC={w_acc:.6f}\\n\")\n",
    "\n",
    "    return df, (mean_auc, mean_acc), (w_auc, w_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd032d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 datasets: ['ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', 'ArrowHead', 'BME', 'Beef', 'BeetleFly', 'BirdChicken', 'CBF', 'Car', 'Chinatown', 'ChlorineConcentration', 'CinCECGTorso', 'Coffee', 'CricketX', 'CricketY', 'CricketZ', 'Crop', 'DiatomSizeReduction', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame', 'DodgerLoopWeekend', 'ECG200', 'ECG5000', 'ECGFiveDays', 'EOGHorizontalSignal', 'EOGVerticalSignal', 'Earthquakes', 'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords', 'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain', 'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan', 'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham', 'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate', 'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound', 'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2', 'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian', 'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxTW', 'MixedShapesRegularTrain', 'MixedShapesSmallTrain', 'MoteStrain', 'NonInvasiveFetalECGThorax1', 'NonInvasiveFetalECGThorax2', 'OSULeaf', 'OliveOil', 'PLAID', 'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ', 'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'Plane', 'PowerCons', 'ProximalPhalanxOutlineAgeGroup', 'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', 'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2', 'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ', 'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarLightCurves', 'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl', 'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG', 'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX', 'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine', 'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga']\n",
      "[ACSF1 | ts2vec] TEST AUC=0.7699, TEST ACC=0.4100, n_samples=100\n",
      "[Adiac | ts2vec] TEST AUC=0.7125, TEST ACC=0.0793, n_samples=391\n",
      "[AllGestureWiimoteX | ts2vec] TEST AUC=0.7093, TEST ACC=0.3671, n_samples=681\n",
      "[AllGestureWiimoteY | ts2vec] TEST AUC=0.7197, TEST ACC=0.3736, n_samples=645\n",
      "[AllGestureWiimoteZ | ts2vec] TEST AUC=0.7800, TEST ACC=0.3489, n_samples=685\n",
      "[ArrowHead | ts2vec] TEST AUC=0.7709, TEST ACC=0.5543, n_samples=175\n",
      "[BME | ts2vec] TEST AUC=0.8308, TEST ACC=0.6867, n_samples=150\n",
      "[Beef | ts2vec] TEST AUC=0.6444, TEST ACC=0.2333, n_samples=30\n",
      "[BeetleFly | ts2vec] TEST AUC=0.7200, TEST ACC=1.0000, n_samples=20\n",
      "[BirdChicken | ts2vec] TEST AUC=0.3700, TEST ACC=1.0000, n_samples=20\n",
      "[CBF | ts2vec] TEST AUC=0.9790, TEST ACC=0.3544, n_samples=900\n",
      "[Car | ts2vec] TEST AUC=0.6504, TEST ACC=0.2167, n_samples=60\n",
      "[Chinatown | ts2vec] TEST AUC=0.9441, TEST ACC=1.0000, n_samples=343\n",
      "[ChlorineConcentration | ts2vec] TEST AUC=0.5327, TEST ACC=0.5380, n_samples=3840\n",
      "[CinCECGTorso | ts2vec] TEST AUC=0.6071, TEST ACC=0.3123, n_samples=1380\n",
      "[Coffee | ts2vec] TEST AUC=1.0000, TEST ACC=1.0000, n_samples=28\n",
      "[CricketX | ts2vec] TEST AUC=0.8094, TEST ACC=0.4026, n_samples=390\n",
      "[CricketY | ts2vec] TEST AUC=0.8357, TEST ACC=0.4462, n_samples=390\n",
      "[CricketZ | ts2vec] TEST AUC=0.8196, TEST ACC=0.3359, n_samples=390\n",
      "[Crop | ts2vec] TEST AUC=0.9235, TEST ACC=0.5522, n_samples=16778\n",
      "[DiatomSizeReduction | ts2vec] TEST AUC=0.5947, TEST ACC=0.3007, n_samples=306\n",
      "[DistalPhalanxOutlineAgeGroup | ts2vec] TEST AUC=0.7098, TEST ACC=0.5758, n_samples=99\n",
      "[DistalPhalanxOutlineCorrect | ts2vec] TEST AUC=0.8031, TEST ACC=1.0000, n_samples=199\n",
      "[DistalPhalanxTW | ts2vec] TEST AUC=0.5861, TEST ACC=0.4149, n_samples=94\n",
      "[DodgerLoopDay | ts2vec] TEST AUC=0.6965, TEST ACC=0.2875, n_samples=80\n",
      "[DodgerLoopGame | ts2vec] TEST AUC=0.6991, TEST ACC=1.0000, n_samples=138\n",
      "[DodgerLoopWeekend | ts2vec] TEST AUC=0.3450, TEST ACC=1.0000, n_samples=138\n",
      "[ECG200 | ts2vec] TEST AUC=0.7391, TEST ACC=1.0000, n_samples=100\n",
      "[ECG5000 | ts2vec] TEST AUC=0.7860, TEST ACC=0.8907, n_samples=4500\n",
      "[ECGFiveDays | ts2vec] TEST AUC=0.8652, TEST ACC=1.0000, n_samples=861\n",
      "[EOGHorizontalSignal | ts2vec] TEST AUC=0.8195, TEST ACC=0.4199, n_samples=362\n",
      "[EOGVerticalSignal | ts2vec] TEST AUC=0.8328, TEST ACC=0.3425, n_samples=362\n",
      "[Earthquakes | ts2vec] TEST AUC=0.6632, TEST ACC=1.0000, n_samples=139\n",
      "[EthanolLevel | ts2vec] TEST AUC=0.5402, TEST ACC=0.2660, n_samples=500\n",
      "[FaceAll | ts2vec] TEST AUC=0.9094, TEST ACC=0.6195, n_samples=1690\n",
      "[FaceFour | ts2vec] TEST AUC=0.4935, TEST ACC=0.3210, n_samples=81\n",
      "[FacesUCR | ts2vec] TEST AUC=0.7479, TEST ACC=0.2620, n_samples=2050\n",
      "[FiftyWords | ts2vec] TEST AUC=0.7915, TEST ACC=0.2571, n_samples=455\n",
      "[Fish | ts2vec] TEST AUC=0.7981, TEST ACC=0.2229, n_samples=175\n",
      "[FordA | ts2vec] TEST AUC=0.9276, TEST ACC=1.0000, n_samples=1320\n",
      "[FordB | ts2vec] TEST AUC=0.7892, TEST ACC=1.0000, n_samples=810\n",
      "[FreezerRegularTrain | ts2vec] TEST AUC=0.8130, TEST ACC=1.0000, n_samples=2850\n",
      "[FreezerSmallTrain | ts2vec] TEST AUC=0.8482, TEST ACC=1.0000, n_samples=2850\n",
      "[Fungi | ts2vec] TEST AUC=0.5275, TEST ACC=0.0591, n_samples=186\n",
      "[GestureMidAirD1 | ts2vec] TEST AUC=0.7701, TEST ACC=0.2923, n_samples=130\n",
      "[GestureMidAirD2 | ts2vec] TEST AUC=0.7566, TEST ACC=0.3308, n_samples=130\n",
      "[GestureMidAirD3 | ts2vec] TEST AUC=0.6523, TEST ACC=0.1846, n_samples=130\n",
      "[GesturePebbleZ1 | ts2vec] TEST AUC=0.7071, TEST ACC=0.3895, n_samples=172\n",
      "[GesturePebbleZ2 | ts2vec] TEST AUC=0.7306, TEST ACC=0.4747, n_samples=158\n",
      "[GunPoint | ts2vec] TEST AUC=0.7930, TEST ACC=1.0000, n_samples=150\n",
      "[GunPointAgeSpan | ts2vec] TEST AUC=0.7613, TEST ACC=1.0000, n_samples=316\n",
      "[GunPointMaleVersusFemale | ts2vec] TEST AUC=0.9992, TEST ACC=1.0000, n_samples=316\n",
      "[GunPointOldVersusYoung | ts2vec] TEST AUC=0.7081, TEST ACC=1.0000, n_samples=315\n",
      "[Ham | ts2vec] TEST AUC=0.6950, TEST ACC=1.0000, n_samples=105\n",
      "[HandOutlines | ts2vec] TEST AUC=0.8991, TEST ACC=1.0000, n_samples=370\n",
      "[Haptics | ts2vec] TEST AUC=0.6284, TEST ACC=0.3442, n_samples=308\n",
      "[Herring | ts2vec] TEST AUC=0.3917, TEST ACC=1.0000, n_samples=64\n",
      "[HouseTwenty | ts2vec] TEST AUC=0.8049, TEST ACC=1.0000, n_samples=119\n",
      "[InlineSkate | ts2vec] TEST AUC=0.5819, TEST ACC=0.1836, n_samples=550\n",
      "[InsectEPGRegularTrain | ts2vec] TEST AUC=0.8339, TEST ACC=0.7390, n_samples=249\n",
      "[InsectEPGSmallTrain | ts2vec] TEST AUC=0.7432, TEST ACC=0.4900, n_samples=249\n",
      "[InsectWingbeatSound | ts2vec] TEST AUC=0.8103, TEST ACC=0.4253, n_samples=1980\n",
      "[ItalyPowerDemand | ts2vec] TEST AUC=0.8908, TEST ACC=1.0000, n_samples=1028\n",
      "[LargeKitchenAppliances | ts2vec] TEST AUC=0.5238, TEST ACC=0.1765, n_samples=17\n",
      "[Lightning2 | ts2vec] TEST AUC=0.5736, TEST ACC=1.0000, n_samples=61\n",
      "[Lightning7 | ts2vec] TEST AUC=0.6567, TEST ACC=0.3562, n_samples=73\n",
      "[Mallat | ts2vec] TEST AUC=0.7261, TEST ACC=0.1232, n_samples=2345\n",
      "[Meat | ts2vec] TEST AUC=0.6071, TEST ACC=0.3333, n_samples=60\n",
      "[MedicalImages | ts2vec] TEST AUC=0.8207, TEST ACC=0.5092, n_samples=760\n",
      "[MelbournePedestrian | ts2vec] TEST AUC=0.8774, TEST ACC=0.6214, n_samples=2425\n",
      "[MiddlePhalanxOutlineAgeGroup | ts2vec] TEST AUC=0.6122, TEST ACC=0.5986, n_samples=147\n",
      "[MiddlePhalanxOutlineCorrect | ts2vec] TEST AUC=0.8146, TEST ACC=1.0000, n_samples=276\n",
      "[MiddlePhalanxTW | ts2vec] TEST AUC=0.4714, TEST ACC=0.4000, n_samples=110\n",
      "[MixedShapesRegularTrain | ts2vec] TEST AUC=0.9362, TEST ACC=0.7629, n_samples=2425\n",
      "[MixedShapesSmallTrain | ts2vec] TEST AUC=0.8716, TEST ACC=0.7361, n_samples=2425\n",
      "[MoteStrain | ts2vec] TEST AUC=0.8733, TEST ACC=1.0000, n_samples=1238\n",
      "[NonInvasiveFetalECGThorax1 | ts2vec] TEST AUC=0.9101, TEST ACC=0.3023, n_samples=1965\n",
      "[NonInvasiveFetalECGThorax2 | ts2vec] TEST AUC=0.9597, TEST ACC=0.5455, n_samples=1965\n",
      "[OSULeaf | ts2vec] TEST AUC=0.7840, TEST ACC=0.3760, n_samples=242\n",
      "[OliveOil | ts2vec] TEST AUC=0.5050, TEST ACC=0.4000, n_samples=30\n",
      "[PLAID | ts2vec] TEST AUC=0.8875, TEST ACC=0.5885, n_samples=537\n",
      "[PhalangesOutlinesCorrect | ts2vec] TEST AUC=0.7825, TEST ACC=1.0000, n_samples=596\n",
      "[Phoneme | ts2vec] TEST AUC=0.5487, TEST ACC=0.1589, n_samples=1894\n",
      "[PickupGestureWiimoteZ | ts2vec] TEST AUC=0.5471, TEST ACC=0.1800, n_samples=50\n",
      "[PigAirwayPressure | ts2vec] TEST AUC=0.5404, TEST ACC=0.0240, n_samples=208\n",
      "[PigArtPressure | ts2vec] TEST AUC=0.6380, TEST ACC=0.0817, n_samples=208\n",
      "[PigCVP | ts2vec] TEST AUC=0.5676, TEST ACC=0.0192, n_samples=208\n",
      "[Plane | ts2vec] TEST AUC=0.9196, TEST ACC=0.3905, n_samples=105\n",
      "[PowerCons | ts2vec] TEST AUC=0.8425, TEST ACC=1.0000, n_samples=180\n",
      "[ProximalPhalanxOutlineAgeGroup | ts2vec] TEST AUC=0.7290, TEST ACC=0.7736, n_samples=106\n",
      "[ProximalPhalanxOutlineCorrect | ts2vec] TEST AUC=0.9541, TEST ACC=1.0000, n_samples=121\n",
      "[ProximalPhalanxTW | ts2vec] TEST AUC=0.5401, TEST ACC=0.5447, n_samples=123\n",
      "[RefrigerationDevices | ts2vec] TEST AUC=0.7431, TEST ACC=0.5742, n_samples=364\n",
      "[Rock | ts2vec] TEST AUC=0.7004, TEST ACC=0.4000, n_samples=50\n",
      "[ScreenType | ts2vec] TEST AUC=0.5618, TEST ACC=0.5167, n_samples=60\n",
      "[SemgHandGenderCh2 | ts2vec] TEST AUC=0.7305, TEST ACC=1.0000, n_samples=600\n",
      "[SemgHandMovementCh2 | ts2vec] TEST AUC=0.7246, TEST ACC=0.3978, n_samples=450\n",
      "[SemgHandSubjectCh2 | ts2vec] TEST AUC=0.8285, TEST ACC=0.5556, n_samples=450\n",
      "[ShakeGestureWiimoteZ | ts2vec] TEST AUC=0.5529, TEST ACC=0.2400, n_samples=50\n",
      "[ShapeletSim | ts2vec] TEST AUC=0.5419, TEST ACC=1.0000, n_samples=180\n",
      "[ShapesAll | ts2vec] TEST AUC=0.9228, TEST ACC=0.6400, n_samples=600\n",
      "[SmallKitchenAppliances | ts2vec] TEST AUC=0.6477, TEST ACC=0.7719, n_samples=57\n",
      "[SonyAIBORobotSurface1 | ts2vec] TEST AUC=0.4922, TEST ACC=1.0000, n_samples=599\n",
      "[SonyAIBORobotSurface2 | ts2vec] TEST AUC=0.8439, TEST ACC=1.0000, n_samples=945\n",
      "[StarLightCurves | ts2vec] TEST AUC=0.9352, TEST ACC=0.8589, n_samples=8236\n",
      "[Strawberry | ts2vec] TEST AUC=0.7507, TEST ACC=1.0000, n_samples=370\n",
      "[SwedishLeaf | ts2vec] TEST AUC=0.9416, TEST ACC=0.5680, n_samples=625\n",
      "[Symbols | ts2vec] TEST AUC=0.7041, TEST ACC=0.1739, n_samples=995\n",
      "[SyntheticControl | ts2vec] TEST AUC=0.9968, TEST ACC=0.9867, n_samples=300\n",
      "[ToeSegmentation1 | ts2vec] TEST AUC=0.8039, TEST ACC=1.0000, n_samples=228\n",
      "[ToeSegmentation2 | ts2vec] TEST AUC=0.7178, TEST ACC=1.0000, n_samples=130\n",
      "[Trace | ts2vec] TEST AUC=0.9385, TEST ACC=0.4800, n_samples=100\n",
      "[TwoLeadECG | ts2vec] TEST AUC=0.9244, TEST ACC=1.0000, n_samples=1139\n",
      "[TwoPatterns | ts2vec] TEST AUC=0.9979, TEST ACC=0.9752, n_samples=3957\n",
      "[UMD | ts2vec] TEST AUC=0.9358, TEST ACC=0.7917, n_samples=144\n",
      "[UWaveGestureLibraryAll | ts2vec] TEST AUC=0.9552, TEST ACC=0.8248, n_samples=3579\n",
      "[UWaveGestureLibraryX | ts2vec] TEST AUC=0.9130, TEST ACC=0.7063, n_samples=3238\n",
      "[UWaveGestureLibraryY | ts2vec] TEST AUC=0.8909, TEST ACC=0.6104, n_samples=3206\n",
      "[UWaveGestureLibraryZ | ts2vec] TEST AUC=0.9130, TEST ACC=0.6370, n_samples=3220\n",
      "[Wafer | ts2vec] TEST AUC=0.9680, TEST ACC=1.0000, n_samples=5935\n",
      "[Wine | ts2vec] TEST AUC=0.4252, TEST ACC=1.0000, n_samples=54\n",
      "[WordSynonyms | ts2vec] TEST AUC=0.6329, TEST ACC=0.2806, n_samples=638\n",
      "[Worms | ts2vec] TEST AUC=0.7370, TEST ACC=0.4286, n_samples=77\n",
      "[WormsTwoClass | ts2vec] TEST AUC=0.7321, TEST ACC=1.0000, n_samples=77\n",
      "[Yoga | ts2vec] TEST AUC=0.6104, TEST ACC=1.0000, n_samples=3000\n",
      "\n",
      "========== Summary (OFFICIAL TEST) ==========\n",
      "                       dataset  test_auc  test_acc  n_samples\n",
      "                         ACSF1  0.769889  0.410000        100\n",
      "                         Adiac  0.712544  0.079284        391\n",
      "            AllGestureWiimoteX  0.709318  0.367107        681\n",
      "            AllGestureWiimoteY  0.719667  0.373643        645\n",
      "            AllGestureWiimoteZ  0.779965  0.348905        685\n",
      "                     ArrowHead  0.770880  0.554286        175\n",
      "                           BME  0.830800  0.686667        150\n",
      "                          Beef  0.644444  0.233333         30\n",
      "                     BeetleFly  0.720000  1.000000         20\n",
      "                   BirdChicken  0.370000  1.000000         20\n",
      "                           CBF  0.979014  0.354444        900\n",
      "                           Car  0.650400  0.216667         60\n",
      "                     Chinatown  0.944117  1.000000        343\n",
      "         ChlorineConcentration  0.532654  0.538021       3840\n",
      "                  CinCECGTorso  0.607139  0.312319       1380\n",
      "                        Coffee  1.000000  1.000000         28\n",
      "                      CricketX  0.809387  0.402564        390\n",
      "                      CricketY  0.835748  0.446154        390\n",
      "                      CricketZ  0.819628  0.335897        390\n",
      "                          Crop  0.923522  0.552152      16778\n",
      "           DiatomSizeReduction  0.594705  0.300654        306\n",
      "  DistalPhalanxOutlineAgeGroup  0.709790  0.575758         99\n",
      "   DistalPhalanxOutlineCorrect  0.803136  1.000000        199\n",
      "               DistalPhalanxTW  0.586092  0.414894         94\n",
      "                 DodgerLoopDay  0.696510  0.287500         80\n",
      "                DodgerLoopGame  0.699074  1.000000        138\n",
      "             DodgerLoopWeekend  0.345044  1.000000        138\n",
      "                        ECG200  0.739149  1.000000        100\n",
      "                       ECG5000  0.786037  0.890667       4500\n",
      "                   ECGFiveDays  0.865225  1.000000        861\n",
      "           EOGHorizontalSignal  0.819454  0.419890        362\n",
      "             EOGVerticalSignal  0.832757  0.342541        362\n",
      "                   Earthquakes  0.663187  1.000000        139\n",
      "                  EthanolLevel  0.540163  0.266000        500\n",
      "                       FaceAll  0.909436  0.619527       1690\n",
      "                      FaceFour  0.493512  0.320988         81\n",
      "                      FacesUCR  0.747857  0.261951       2050\n",
      "                    FiftyWords  0.791535  0.257143        455\n",
      "                          Fish  0.798051  0.222857        175\n",
      "                         FordA  0.927590  1.000000       1320\n",
      "                         FordB  0.789207  1.000000        810\n",
      "           FreezerRegularTrain  0.813045  1.000000       2850\n",
      "             FreezerSmallTrain  0.848155  1.000000       2850\n",
      "                         Fungi  0.527504  0.059140        186\n",
      "               GestureMidAirD1  0.770092  0.292308        130\n",
      "               GestureMidAirD2  0.756615  0.330769        130\n",
      "               GestureMidAirD3  0.652308  0.184615        130\n",
      "               GesturePebbleZ1  0.707057  0.389535        172\n",
      "               GesturePebbleZ2  0.730614  0.474684        158\n",
      "                      GunPoint  0.793030  1.000000        150\n",
      "               GunPointAgeSpan  0.761258  1.000000        316\n",
      "      GunPointMaleVersusFemale  0.999237  1.000000        316\n",
      "        GunPointOldVersusYoung  0.708121  1.000000        315\n",
      "                           Ham  0.694989  1.000000        105\n",
      "                  HandOutlines  0.899051  1.000000        370\n",
      "                       Haptics  0.628411  0.344156        308\n",
      "                       Herring  0.391700  1.000000         64\n",
      "                   HouseTwenty  0.804928  1.000000        119\n",
      "                   InlineSkate  0.581945  0.183636        550\n",
      "         InsectEPGRegularTrain  0.833906  0.738956        249\n",
      "           InsectEPGSmallTrain  0.743153  0.489960        249\n",
      "           InsectWingbeatSound  0.810331  0.425253       1980\n",
      "              ItalyPowerDemand  0.890827  1.000000       1028\n",
      "        LargeKitchenAppliances  0.523810  0.176471         17\n",
      "                    Lightning2  0.573593  1.000000         61\n",
      "                    Lightning7  0.656703  0.356164         73\n",
      "                        Mallat  0.726128  0.123241       2345\n",
      "                          Meat  0.607083  0.333333         60\n",
      "                 MedicalImages  0.820680  0.509211        760\n",
      "           MelbournePedestrian  0.877359  0.621443       2425\n",
      "  MiddlePhalanxOutlineAgeGroup  0.612246  0.598639        147\n",
      "   MiddlePhalanxOutlineCorrect  0.814600  1.000000        276\n",
      "               MiddlePhalanxTW  0.471432  0.400000        110\n",
      "       MixedShapesRegularTrain  0.936208  0.762887       2425\n",
      "         MixedShapesSmallTrain  0.871612  0.736082       2425\n",
      "                    MoteStrain  0.873307  1.000000       1238\n",
      "    NonInvasiveFetalECGThorax1  0.910142  0.302290       1965\n",
      "    NonInvasiveFetalECGThorax2  0.959667  0.545547       1965\n",
      "                       OSULeaf  0.783954  0.376033        242\n",
      "                      OliveOil  0.504969  0.400000         30\n",
      "                         PLAID  0.887479  0.588454        537\n",
      "      PhalangesOutlinesCorrect  0.782494  1.000000        596\n",
      "                       Phoneme  0.548687  0.158923       1894\n",
      "         PickupGestureWiimoteZ  0.547111  0.180000         50\n",
      "             PigAirwayPressure  0.540394  0.024038        208\n",
      "                PigArtPressure  0.637962  0.081731        208\n",
      "                        PigCVP  0.567590  0.019231        208\n",
      "                         Plane  0.919645  0.390476        105\n",
      "                     PowerCons  0.842469  1.000000        180\n",
      "ProximalPhalanxOutlineAgeGroup  0.728977  0.773585        106\n",
      " ProximalPhalanxOutlineCorrect  0.954088  1.000000        121\n",
      "             ProximalPhalanxTW  0.540103  0.544715        123\n",
      "          RefrigerationDevices  0.743104  0.574176        364\n",
      "                          Rock  0.700390  0.400000         50\n",
      "                    ScreenType  0.561784  0.516667         60\n",
      "             SemgHandGenderCh2  0.730476  1.000000        600\n",
      "           SemgHandMovementCh2  0.724616  0.397778        450\n",
      "            SemgHandSubjectCh2  0.828475  0.555556        450\n",
      "          ShakeGestureWiimoteZ  0.552889  0.240000         50\n",
      "                   ShapeletSim  0.541852  1.000000        180\n",
      "                     ShapesAll  0.922788  0.640000        600\n",
      "        SmallKitchenAppliances  0.647697  0.771930         57\n",
      "         SonyAIBORobotSurface1  0.492248  1.000000        599\n",
      "         SonyAIBORobotSurface2  0.843851  1.000000        945\n",
      "               StarLightCurves  0.935176  0.858912       8236\n",
      "                    Strawberry  0.750732  1.000000        370\n",
      "                   SwedishLeaf  0.941616  0.568000        625\n",
      "                       Symbols  0.704126  0.173869        995\n",
      "              SyntheticControl  0.996827  0.986667        300\n",
      "              ToeSegmentation1  0.803935  1.000000        228\n",
      "              ToeSegmentation2  0.717767  1.000000        130\n",
      "                         Trace  0.938472  0.480000        100\n",
      "                    TwoLeadECG  0.924392  1.000000       1139\n",
      "                   TwoPatterns  0.997902  0.975234       3957\n",
      "                           UMD  0.935836  0.791667        144\n",
      "        UWaveGestureLibraryAll  0.955150  0.824811       3579\n",
      "          UWaveGestureLibraryX  0.913041  0.706300       3238\n",
      "          UWaveGestureLibraryY  0.890862  0.610418       3206\n",
      "          UWaveGestureLibraryZ  0.913011  0.636957       3220\n",
      "                         Wafer  0.968022  1.000000       5935\n",
      "                          Wine  0.425240  1.000000         54\n",
      "                  WordSynonyms  0.632950  0.280564        638\n",
      "                         Worms  0.736968  0.428571         77\n",
      "                 WormsTwoClass  0.732094  1.000000         77\n",
      "                          Yoga  0.610377  1.000000       3000\n",
      "\n",
      "Simple mean: AUC = 0.7468, ACC = 0.6218\n",
      "Weighted (by samples): AUC = 0.8413, ACC = 0.6800\n"
     ]
    }
   ],
   "source": [
    "# 只跑 TS2Vec（自监督 + 线性探针）\n",
    "_ = run_all_datasets(\n",
    "    root=ROOT,\n",
    "    device='cuda:0',\n",
    "    batch_size=8,\n",
    "    num_epochs=100,   # 用作线性头训练的 epoch；自监督迭代走默认\n",
    "    lr=1e-4,          # 为公平也可用同 lr\n",
    "    cap_len=None,\n",
    "    verbose=False,\n",
    "    plot_curves=True,\n",
    "    patience=15,\n",
    "    backbone='ts2vec'   # ← 关键\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
